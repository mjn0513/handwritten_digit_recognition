

## 人工智能导论第三次实验报告

2020302579 毛佳凝

## 1.实验名称：MNIST手写体识别实验

## 2.算法思想：

### （1）MNIST：

MNIST全称是 **Mixed National Institute of Standards and Technology database** ，来自美国国家标准与技术研究所，是NIST（National Institute of Standards and Technology）的缩小版。训练集（training set）由来自 250 个不同人手写的数字构成，其中 50% 是高中学生，50% 来自人口普查局（the Census Bureau）的工作人员，数量为60000。测试集（test set）也是同样比例的手写数字数据，数量为10000，总共有70000个数据。

MNIST数据集可以在官网中下载，即

![image-20221228144346413](C:\Users\mjn\AppData\Roaming\Typora\typora-user-images\image-20221228144346413.png)

在此次实验中我使用python命令直接自动下载。

MNIST数据集共有70000张图片，图片的规格均是28\*28，所以一张图片的像素值为784，故以传统神经网络来看, 可以设置二维数组[70000] [784]，而每张图片每个像素点值介于 0~1 之间,即数组元素值在0~1之间

### （2）神经网络：

- 神经元：

  神经网络由大量的神经元相互连接而成。每个神经元接受线性组合的输入后，最开始只是简单的线性加权，后来给每个神经元加上了非线性的激活函数，从而进行非线性变换后输出。每两个神经元之间的连接代表加权值，称之为权重。不同的权重和激活函数，则会导致神经网络不同的输出。如下图示：

  ![img](https://img-blog.csdn.net/20160716131107406)

  ~~~
   基本wx + b的形式，其中
  
  x1、x2表示输入向量
  w1、w2为权重，几个输入则意味着有几个权重，即每个输入都被赋予一个权重
  b为偏置bias
  g(z) 为激活函数
  a 为输出
  ~~~

- 激活函数

  常用的非线性激活函数有sigmoid、tanh、relu等等，前两者sigmoid/tanh比较常见于全连接层，后者relu常见于卷积层。

- 神经网络

  将神经元组织在一起便形成了神经网络，如下图示：

  ![image-20221223155717253](C:\Users\mjn\AppData\Roaming\Typora\typora-user-images\image-20221223155717253.png)

  - 输入层：input layer,众多神经元（Neuron）接受大量非线形输入讯息。输入的讯息称为输入向量。
  - 输出层：output layer,讯息在神经元链接中传输、分析、权衡，形成输出结果。输出的讯息称为输出向量。
  - 隐藏层：hidden layer,是输入层和输出层之间众多神经元和链接组成的各个层面。如果有多个隐藏层，则意味着多个激活函数。

- 卷积神经网络的层次结构

  例如汽车识别系统：

  ![img](https://img-blog.csdn.net/20160702205047459)

   此图中，左侧为数据输入层，对数据进行处理，如去均值，归一化；中间为CONV（卷积计算层）；RELU（激励层）；POOL(池化层)；右侧为FC（全连接层）

- 卷积

   对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的卷积操作，也是卷积神经网络的名字来源。下图中红框框起来的部分便可以理解为一个滤波器，即带着一组固定权重的神经元。多个滤波器叠加便成了卷积层。

  ![img](https://img-blog.csdn.net/20160822134955264)

### 

- 获得数据，并将数据处理成合适的格式
- 按照自己的设计搭建神经网络
- 设定合适的参数训练神经网络
- 在测试集上评价训练效果

## 3.算法设计

- 获得数据，并将数据处理成合适的格式

  加载MNIST数据库集，将二维矩阵转换为一维向量

- 搭建神经元模型

- 设定合适的参数训练神经网络

- 在测试集上评价训练效果

## 4.代码设计

- 导包

~~~
from keras.utils import to_categorical
from keras import models, layers, regularizers
from keras.optimizers import RMSprop
from keras.datasets import mnist
import matplotlib.pyplot as plt
~~~

- 加载数据集，测试是否能正确输出

~~~
# 加载数据集
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()  
# test1
print(train_images.shape, test_images.shape)
print(train_images[0])
print(train_labels[0])
plt.imshow(train_images[0])     
plt.show()
~~~

~~~
#测试输出：
D:\workplace\anaconda\python.exe D:\workplace\pythonProject4\main.py 
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434 [==============================] - 2s 0us/step
(60000, 28, 28) (10000, 28, 28)
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136
  175  26 166 255 247 127   0   0   0   0]
 [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253
  225 172 253 242 195  64   0   0   0   0]
 [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251
   93  82  82  56  39   0   0   0   0   0]
 [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119
   25   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253
  150  27   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252
  253 187   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249
  253 249  64   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253
  253 207   2   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253
  250 182   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201
   78   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]]
5

~~~

![image-20221228102257441](C:\Users\mjn\AppData\Roaming\Typora\typora-user-images\image-20221228102257441.png)

- 将28*28矩阵压缩为向量：

~~~
train_images = train_images.reshape((60000, 28*28)).astype('float')
test_images = test_images.reshape((10000, 28*28)).astype('float')
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

~~~

- 测试2：

~~~
print(train_labels[0])
~~~

- 测试输出：

~~~
D:\workplace\anaconda\python.exe D:\workplace\pythonProject4\main.py 
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]

Process finished with exit code 0

~~~

- 建设神经元模型：

~~~
network = models.Sequential()
network.add(layers.Dense(units=15, activation='relu', input_shape=(28*28, ),))
network.add(layers.Dense(units=10, activation='softmax'))
~~~

- test3:查看神经网络结构

~~~
print(network.summary())
~~~

- 测试输出：

~~~
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 15)                11775     
                                                                 
 dense_1 (Dense)             (None, 10)                160       
                                                                 
=================================================================
Total params: 11,935
Trainable params: 11,935
Non-trainable params: 0
_________________________________________________________________
None

Process finished with exit code 0
~~~

  （第一个隐藏层神经元个数为15，可训练参数为111775）

- 神经网络训练：

~~~
#确定优化器和损失函数等
# 编译步骤
network.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
#训练网络
network.fit(train_images, train_labels, epochs=20, batch_size=128, verbose=2)
~~~

- test4：使用训练集进行测试，结果如下

~~~
Epoch 1/20
469/469 - 2s - loss: 2.8756 - accuracy: 0.2800 - 2s/epoch - 3ms/step
Epoch 2/20
469/469 - 1s - loss: 1.5451 - accuracy: 0.4497 - 790ms/epoch - 2ms/step
Epoch 3/20
469/469 - 1s - loss: 1.2560 - accuracy: 0.5639 - 769ms/epoch - 2ms/step
Epoch 4/20
469/469 - 1s - loss: 1.0757 - accuracy: 0.6223 - 818ms/epoch - 2ms/step
Epoch 5/20
469/469 - 1s - loss: 0.9479 - accuracy: 0.6691 - 773ms/epoch - 2ms/step
Epoch 6/20
469/469 - 1s - loss: 0.8645 - accuracy: 0.7196 - 802ms/epoch - 2ms/step
Epoch 7/20
469/469 - 1s - loss: 0.8120 - accuracy: 0.7461 - 980ms/epoch - 2ms/step
Epoch 8/20
469/469 - 1s - loss: 0.7193 - accuracy: 0.7972 - 904ms/epoch - 2ms/step
Epoch 9/20
469/469 - 1s - loss: 0.6336 - accuracy: 0.8200 - 791ms/epoch - 2ms/step
Epoch 10/20
469/469 - 1s - loss: 0.5486 - accuracy: 0.8471 - 740ms/epoch - 2ms/step
Epoch 11/20
469/469 - 1s - loss: 0.4899 - accuracy: 0.8644 - 1s/epoch - 3ms/step
Epoch 12/20
469/469 - 2s - loss: 0.4707 - accuracy: 0.8706 - 2s/epoch - 3ms/step
Epoch 13/20
469/469 - 2s - loss: 0.4543 - accuracy: 0.8730 - 2s/epoch - 3ms/step
Epoch 14/20
469/469 - 1s - loss: 0.4380 - accuracy: 0.8783 - 1s/epoch - 2ms/step
Epoch 15/20
469/469 - 1s - loss: 0.4262 - accuracy: 0.8805 - 806ms/epoch - 2ms/step
Epoch 16/20
469/469 - 1s - loss: 0.4206 - accuracy: 0.8816 - 815ms/epoch - 2ms/step
Epoch 17/20
469/469 - 1s - loss: 0.4145 - accuracy: 0.8853 - 765ms/epoch - 2ms/step
Epoch 18/20
469/469 - 1s - loss: 0.4058 - accuracy: 0.8877 - 793ms/epoch - 2ms/step
Epoch 19/20
469/469 - 1s - loss: 0.3992 - accuracy: 0.8918 - 907ms/epoch - 2ms/step
Epoch 20/20
469/469 - 1s - loss: 0.3907 - accuracy: 0.8942 - 796ms/epoch - 2ms/step

Process finished with exit code 0
~~~

- 使用测试集进行测试：

~~~
y_pre = network.predict(test_images[:5])
print(y_pre, test_labels[:5])
test_loss, test_accuracy = network.evaluate(test_images, test_labels)
print("test_loss:", test_loss, "    test_accuracy:", test_accuracy)
~~~

- 测试结果：

~~~
Epoch 1/20
469/469 - 1s - loss: 2.8019 - accuracy: 0.2669 - 1s/epoch - 3ms/step
Epoch 2/20
469/469 - 1s - loss: 1.5302 - accuracy: 0.4555 - 821ms/epoch - 2ms/step
Epoch 3/20
469/469 - 1s - loss: 1.2416 - accuracy: 0.5555 - 837ms/epoch - 2ms/step
Epoch 4/20
469/469 - 1s - loss: 1.0808 - accuracy: 0.6008 - 760ms/epoch - 2ms/step
Epoch 5/20
469/469 - 1s - loss: 0.9659 - accuracy: 0.6497 - 783ms/epoch - 2ms/step
Epoch 6/20
469/469 - 1s - loss: 0.8782 - accuracy: 0.6934 - 806ms/epoch - 2ms/step
Epoch 7/20
469/469 - 1s - loss: 0.8109 - accuracy: 0.7289 - 729ms/epoch - 2ms/step
Epoch 8/20
469/469 - 1s - loss: 0.7592 - accuracy: 0.7527 - 765ms/epoch - 2ms/step
Epoch 9/20
469/469 - 1s - loss: 0.7136 - accuracy: 0.7687 - 817ms/epoch - 2ms/step
Epoch 10/20
469/469 - 1s - loss: 0.6721 - accuracy: 0.7908 - 819ms/epoch - 2ms/step
Epoch 11/20
469/469 - 1s - loss: 0.6267 - accuracy: 0.8280 - 848ms/epoch - 2ms/step
Epoch 12/20
469/469 - 1s - loss: 0.5636 - accuracy: 0.8542 - 752ms/epoch - 2ms/step
Epoch 13/20
469/469 - 1s - loss: 0.5089 - accuracy: 0.8718 - 844ms/epoch - 2ms/step
Epoch 14/20
469/469 - 1s - loss: 0.4759 - accuracy: 0.8779 - 751ms/epoch - 2ms/step
Epoch 15/20
469/469 - 1s - loss: 0.4533 - accuracy: 0.8840 - 752ms/epoch - 2ms/step
Epoch 16/20
469/469 - 1s - loss: 0.4334 - accuracy: 0.8889 - 761ms/epoch - 2ms/step
Epoch 17/20
469/469 - 1s - loss: 0.4214 - accuracy: 0.8907 - 818ms/epoch - 2ms/step
Epoch 18/20
469/469 - 1s - loss: 0.4058 - accuracy: 0.8926 - 793ms/epoch - 2ms/step
Epoch 19/20
469/469 - 1s - loss: 0.3966 - accuracy: 0.8956 - 786ms/epoch - 2ms/step
Epoch 20/20
469/469 - 1s - loss: 0.3855 - accuracy: 0.8999 - 785ms/epoch - 2ms/step
1/1 [==============================] - 0s 83ms/step
[[0.00000000e+00 4.08830747e-05 1.24213975e-05 1.65886631e-05
  5.36039391e-09 1.32442025e-07 1.12660836e-31 9.99892354e-01
  1.09941765e-12 3.76582284e-05]
 [1.96320258e-08 4.22468074e-05 9.69730258e-01 1.70216803e-02
  7.34305358e-04 6.32076353e-06 1.21012069e-02 3.61250131e-04
  2.82701444e-06 9.15323373e-11]
 [1.08841360e-27 9.99980092e-01 6.69370365e-07 3.89497574e-29
  5.46574373e-16 9.39128259e-18 4.99224596e-16 2.06857703e-06
  1.71692427e-05 3.34685965e-22]
 [9.21539903e-01 2.87202559e-03 1.99198406e-02 1.42289586e-02
  1.50240539e-03 2.86363065e-03 2.79363571e-03 4.67762491e-03
  2.60559693e-02 3.54602188e-03]
 [1.42466171e-13 6.52177609e-04 5.73699072e-04 1.53487157e-02
  9.01876926e-01 2.09269114e-04 4.47493003e-05 5.96678406e-02
  4.91967541e-04 2.11347565e-02]] [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
313/313 [==============================] - 1s 1ms/step - loss: 0.4942 - accuracy: 0.8963
test_loss: 0.4941502809524536     test_accuracy: 0.8963000178337097

Process finished with exit code 0

~~~

**由此可见，正确率：89.63%**

#### 为了提高正确率，进行改进：卷积神经网络

- 源代码：

~~~
from keras.utils import to_categorical
from keras import models, layers
from keras.optimizers import RMSprop
from keras.datasets import mnist
# 加载数据集
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# 搭建LeNet网络
def LeNet():
    network = models.Sequential()
    network.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
    network.add(layers.AveragePooling2D((2, 2)))
    network.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
    network.add(layers.AveragePooling2D((2, 2)))
    network.add(layers.Conv2D(filters=120, kernel_size=(3, 3), activation='relu'))
    network.add(layers.Flatten())
    network.add(layers.Dense(84, activation='relu'))
    network.add(layers.Dense(10, activation='softmax'))
    return network
network = LeNet()
network.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

train_images = train_images.reshape((60000, 28, 28, 1)).astype('float') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# 训练网络，用fit函数, epochs表示训练回合， batch_size表示每次训练数据量
network.fit(train_images, train_labels, epochs=10, batch_size=128, verbose=2)
test_loss, test_accuracy = network.evaluate(test_images, test_labels)
print("test_loss:", test_loss, "    test_accuracy:", test_accuracy)
~~~

- **改进：**

1.第一个隐藏层的神经元个数增加

2.添加一个隐藏层

- 输出：

~~~
Epoch 1/10
469/469 - 11s - loss: 0.3759 - accuracy: 0.8855 - 11s/epoch - 24ms/step
Epoch 2/10
469/469 - 9s - loss: 0.1037 - accuracy: 0.9686 - 9s/epoch - 20ms/step
Epoch 3/10
469/469 - 10s - loss: 0.0671 - accuracy: 0.9793 - 10s/epoch - 22ms/step
Epoch 4/10
469/469 - 10s - loss: 0.0505 - accuracy: 0.9847 - 10s/epoch - 21ms/step
Epoch 5/10
469/469 - 9s - loss: 0.0413 - accuracy: 0.9873 - 9s/epoch - 18ms/step
Epoch 6/10
469/469 - 10s - loss: 0.0340 - accuracy: 0.9890 - 10s/epoch - 20ms/step
Epoch 7/10
469/469 - 10s - loss: 0.0293 - accuracy: 0.9908 - 10s/epoch - 21ms/step
Epoch 8/10
469/469 - 10s - loss: 0.0251 - accuracy: 0.9923 - 10s/epoch - 22ms/step
Epoch 9/10
469/469 - 10s - loss: 0.0219 - accuracy: 0.9932 - 10s/epoch - 21ms/step
Epoch 10/10
469/469 - 10s - loss: 0.0194 - accuracy: 0.9940 - 10s/epoch - 21ms/step
313/313 [==============================] - 2s 6ms/step - loss: 0.0344 - accuracy: 0.9900
test_loss: 0.03438970819115639     test_accuracy: 0.9900000095367432

Process finished with exit code 0

~~~

由数据可得，在训练集上准确率为99.4%，在测试集上的准确率为99%

## 5.源代码

全连接神经网络：（源代码见pythonProject4.py）

~~~
# print(train_images[0])
# print(train_labels[0])
# plt.imshow(train_images[0])     # 使用python自带画图软件绘制train_images
# plt.show()

# 压缩向量
train_images = train_images.reshape((60000, 28*28)).astype('float')   # 将二维矩阵压缩为一维向量，将数据剋行转换为float
test_images = test_images.reshape((10000, 28*28)).astype('float')
train_labels = to_categorical(train_labels)           # 将train_labels重新编码，数组中第n位为1则数组表示为n
test_labels = to_categorical(test_labels)
# test2：输出第0张图片的所示数字，由上述已知第0张图片所示数字为5，则输出应该为[0 0 0 0 0 1 0 0 0 0]
# print(train_labels[0])

# 搭建神经网络
network = models.Sequential()
network.add(layers.Dense(units=15, activation='relu', input_shape=(28*28, ),))
network.add(layers.Dense(units=10, activation='softmax'))
# test3：搭建的神经网络的信息
# print(network.summary())

# 编译步骤
network.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
# 训练网络，用fit函数, epochs表示训练多少个回合， batch_size表示每次训练给多大的数据
network.fit(train_images, train_labels, epochs=20, batch_size=128, verbose=2)

# 使用测试集进行测试
y_pre = network.predict(test_images[:5])
print(y_pre, test_labels[:5])
test_loss, test_accuracy = network.evaluate(test_images, test_labels)
print("test_loss:", test_loss, "    test_accuracy:", test_accuracy)
~~~

卷积神经网络：（源代码见pythonProject5_mnist2）

~~~
from keras.utils import to_categorical
from keras import models, layers
from keras.optimizers import RMSprop
from keras.datasets import mnist
# 加载数据集
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# 搭建LeNet网络
def LeNet():
    network = models.Sequential()
    network.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
    network.add(layers.AveragePooling2D((2, 2)))
    network.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
    network.add(layers.AveragePooling2D((2, 2)))
    network.add(layers.Conv2D(filters=120, kernel_size=(3, 3), activation='relu'))
    network.add(layers.Flatten())
    network.add(layers.Dense(84, activation='relu'))
    network.add(layers.Dense(10, activation='softmax'))
    return network
network = LeNet()
network.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

train_images = train_images.reshape((60000, 28, 28, 1)).astype('float') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# 训练网络，用fit函数, epochs表示训练多少个回合， batch_size表示每次训练给多大的数据
network.fit(train_images, train_labels, epochs=10, batch_size=128, verbose=2)
test_loss, test_accuracy = network.evaluate(test_images, test_labels)
print("test_loss:", test_loss, "    test_accuracy:", test_accuracy)

~~~

## 6.实验测试

- 全连接神经网络测试集：

~~~
y_pre = network.predict(test_images[:5])
print(y_pre, test_labels[:5])
test_loss, test_accuracy = network.evaluate(test_images, test_labels)
print("test_loss:", test_loss, "    test_accuracy:", test_accuracy)
~~~

- 测试结果：

~~~
Epoch 1/20
469/469 - 1s - loss: 2.8019 - accuracy: 0.2669 - 1s/epoch - 3ms/step
Epoch 2/20
469/469 - 1s - loss: 1.5302 - accuracy: 0.4555 - 821ms/epoch - 2ms/step
Epoch 3/20
469/469 - 1s - loss: 1.2416 - accuracy: 0.5555 - 837ms/epoch - 2ms/step
Epoch 4/20
469/469 - 1s - loss: 1.0808 - accuracy: 0.6008 - 760ms/epoch - 2ms/step
Epoch 5/20
469/469 - 1s - loss: 0.9659 - accuracy: 0.6497 - 783ms/epoch - 2ms/step
Epoch 6/20
469/469 - 1s - loss: 0.8782 - accuracy: 0.6934 - 806ms/epoch - 2ms/step
Epoch 7/20
469/469 - 1s - loss: 0.8109 - accuracy: 0.7289 - 729ms/epoch - 2ms/step
Epoch 8/20
469/469 - 1s - loss: 0.7592 - accuracy: 0.7527 - 765ms/epoch - 2ms/step
Epoch 9/20
469/469 - 1s - loss: 0.7136 - accuracy: 0.7687 - 817ms/epoch - 2ms/step
Epoch 10/20
469/469 - 1s - loss: 0.6721 - accuracy: 0.7908 - 819ms/epoch - 2ms/step
Epoch 11/20
469/469 - 1s - loss: 0.6267 - accuracy: 0.8280 - 848ms/epoch - 2ms/step
Epoch 12/20
469/469 - 1s - loss: 0.5636 - accuracy: 0.8542 - 752ms/epoch - 2ms/step
Epoch 13/20
469/469 - 1s - loss: 0.5089 - accuracy: 0.8718 - 844ms/epoch - 2ms/step
Epoch 14/20
469/469 - 1s - loss: 0.4759 - accuracy: 0.8779 - 751ms/epoch - 2ms/step
Epoch 15/20
469/469 - 1s - loss: 0.4533 - accuracy: 0.8840 - 752ms/epoch - 2ms/step
Epoch 16/20
469/469 - 1s - loss: 0.4334 - accuracy: 0.8889 - 761ms/epoch - 2ms/step
Epoch 17/20
469/469 - 1s - loss: 0.4214 - accuracy: 0.8907 - 818ms/epoch - 2ms/step
Epoch 18/20
469/469 - 1s - loss: 0.4058 - accuracy: 0.8926 - 793ms/epoch - 2ms/step
Epoch 19/20
469/469 - 1s - loss: 0.3966 - accuracy: 0.8956 - 786ms/epoch - 2ms/step
Epoch 20/20
469/469 - 1s - loss: 0.3855 - accuracy: 0.8999 - 785ms/epoch - 2ms/step
1/1 [==============================] - 0s 83ms/step
[[0.00000000e+00 4.08830747e-05 1.24213975e-05 1.65886631e-05
  5.36039391e-09 1.32442025e-07 1.12660836e-31 9.99892354e-01
  1.09941765e-12 3.76582284e-05]
 [1.96320258e-08 4.22468074e-05 9.69730258e-01 1.70216803e-02
  7.34305358e-04 6.32076353e-06 1.21012069e-02 3.61250131e-04
  2.82701444e-06 9.15323373e-11]
 [1.08841360e-27 9.99980092e-01 6.69370365e-07 3.89497574e-29
  5.46574373e-16 9.39128259e-18 4.99224596e-16 2.06857703e-06
  1.71692427e-05 3.34685965e-22]
 [9.21539903e-01 2.87202559e-03 1.99198406e-02 1.42289586e-02
  1.50240539e-03 2.86363065e-03 2.79363571e-03 4.67762491e-03
  2.60559693e-02 3.54602188e-03]
 [1.42466171e-13 6.52177609e-04 5.73699072e-04 1.53487157e-02
  9.01876926e-01 2.09269114e-04 4.47493003e-05 5.96678406e-02
  4.91967541e-04 2.11347565e-02]] [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
313/313 [==============================] - 1s 1ms/step - loss: 0.4942 - accuracy: 0.8963
test_loss: 0.4941502809524536     test_accuracy: 0.8963000178337097

Process finished with exit code 0

~~~

- 卷积神经网络测试集：

~~~
network.fit(train_images, train_labels, epochs=10, batch_size=128, verbose=2)
test_loss, test_accuracy = network.evaluate(test_images, test_labels)
print("test_loss:", test_loss, "    test_accuracy:", test_accuracy)
~~~

- 测试结果：

~~~
Epoch 1/10
469/469 - 11s - loss: 0.3759 - accuracy: 0.8855 - 11s/epoch - 24ms/step
Epoch 2/10
469/469 - 9s - loss: 0.1037 - accuracy: 0.9686 - 9s/epoch - 20ms/step
Epoch 3/10
469/469 - 10s - loss: 0.0671 - accuracy: 0.9793 - 10s/epoch - 22ms/step
Epoch 4/10
469/469 - 10s - loss: 0.0505 - accuracy: 0.9847 - 10s/epoch - 21ms/step
Epoch 5/10
469/469 - 9s - loss: 0.0413 - accuracy: 0.9873 - 9s/epoch - 18ms/step
Epoch 6/10
469/469 - 10s - loss: 0.0340 - accuracy: 0.9890 - 10s/epoch - 20ms/step
Epoch 7/10
469/469 - 10s - loss: 0.0293 - accuracy: 0.9908 - 10s/epoch - 21ms/step
Epoch 8/10
469/469 - 10s - loss: 0.0251 - accuracy: 0.9923 - 10s/epoch - 22ms/step
Epoch 9/10
469/469 - 10s - loss: 0.0219 - accuracy: 0.9932 - 10s/epoch - 21ms/step
Epoch 10/10
469/469 - 10s - loss: 0.0194 - accuracy: 0.9940 - 10s/epoch - 21ms/step
313/313 [==============================] - 2s 6ms/step - loss: 0.0344 - accuracy: 0.9900
test_loss: 0.03438970819115639     test_accuracy: 0.9900000095367432

Process finished with exit code 0
~~~

## 7，结论

这次实验令我收益匪浅，在此次实验中，我认识了神经网络以及MNIST，了解了神经网络的应用场景，作用以及训练步骤，并通过手写数字识别的小实验成功完成了一次神经网络训练的尝试，并对方法和正确率做出了分析和改进。这次实验用时较长，主要在下载tensorflow时遇到了较多的问题，首先我使用cmd中pip指令尝试下载tensorflow，经历多次失败后我首先更新了我的python版本，下载了Anaconda，并使pycharm连接使用了anaconda环境，并成功在anaconda环境中下载了tensorflow,进而完成了实验，我从中了解了python的不同库和虚拟环境，通过这次实验我学习到了新的知识，并深刻认识到了实践的重要性，纸上得来终觉浅，绝知此事要躬行。

